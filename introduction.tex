\section{Introduction}

The last decade has seen a tremendous growth in content available in
the World Wide Web, and, more specifically, in information generated
from online social networks. The structure of such content is usually
a graph, a very flexible structure suited to represent content where
pairs of items are linked.  In order to process such information,
there has been an increased interest in running graph-based algorithms
concurrently and efficiently on top of distributed networks and
computer architectures (multicores).  Currently available libraries
and frameworks are built on top of imperative programming languages,
which require the programmer to know how to properly use the framework
and the language. Reasoning about such programs requires knowing the
intricacies of the framework, how computation is scheduled and how
processing units coordinate between each other.

Some well known frameworks include Dryad, Pregel and GraphLab.  The
Dryad system~\cite{Isard:2007:DDD:1272996.1273005} combines
computational vertices with communication channels (edges) to form a
data-flow graph. The program is scheduled to run on multiple
processors or cores and data is partitioned during runtime. Routines
that run on computational vertices are sequential, with no
synchronization.  The Pregel
system~\cite{Malewicz:2010:PSL:1807167.1807184} is also graph based,
although programs have a more strict structure. They must be
represented as a sequence of iterations where each iteration is
composed of computation and message passing.  Pregel is specially
suited to work on big graphs and to scale to large architectures.
GraphLab~\cite{GraphLab2010} is a C++ framework for developing
parallel machine learning algorithms. While Pregel uses message
passing, GraphLab allows nodes to have read/write access to different
scopes through different concurrent access models in order to balance
performance and data consistency. While some programs only need to
access the local node's data, others may need to update edge
information. Each consistency model will provide different guarantees
that are better adapted to some algorithms. GraphLab also provides
different schedulers that dictate the order in which node's are
computed.

Logic programming is an attractive approach to the graph-based algorithms,
since logic-based languages provide a high-level, declarative approach
to programming. An important characteristic of logic programming is
that it offers great potential for implicit parallelism, thus making
logic programs much easier to parallelize than imperative
programs. First, logic programs are easier to reason about since they
are based on logical foundations. Second, logic programmers do not
need to use low level programming constructs such as locks or
semaphores to coordinate parallel execution, because logic systems
hide such details from the programmer.

Logic programming split into two main groups:
\emph{backwards-chaining} and \emph{forward-chaining} languages. In a
backwards-chaining programming language, programs are composed of a
set of rules that can be activated by inputting a query. Given a query
$q(\hat{x})$, an interpreter will work backwards by matching
$q(\hat{x})$ against the head of a rule. If found, the interpreter
will then try to match the body of the rule, recursively, until it
finds the program axioms (rules without body). If the search procedure
succeeds, the interpreter finds a valid substitution for the $\hat{x}$
variables. A popular backwards-chaining programming language is
Prolog~\cite{Colmerauer:1993:BP:154766.155362}, which has been a
productive research language for executing logic programs in
parallel. Researchers took advantage of Prolog's non-determinism to
evaluate subgoals in parallel with models such as
\emph{And-parallelism} and
\emph{Or-parallelism}~\cite{Gupta:2001:PEP:504083.504085}.

In a forward-chaining logic programming language, programs start with
a database of facts (filled with the program's axioms) and a set of
logical rules. The database of facts is then used to fire the
program's rules and derive new facts that are then added to the
database. This process is repeated recursively until the database
reaches \emph{quiescence} and no more information can be derived from
the program. A popular forward-chaining programming language is
Datalog~\cite{Ramakrishnan93asurvey}.

We have designed Linear Meld~(LM), a forward-chaining logic programming
language that is specially suited for
concurrent programming over graph structures~\cite{cruz-iclp14}. LM
differs from Datalog-like languages because it integrates both
classical logic and linear logic~\cite{girard-87} into the language, allowing some
facts to be retracted and asserted in a logical fashion. Although most
Datalog and Prolog-like programming languages allow some kind of state
manipulation~\cite{Liu98extendingdatalog}, those features are
extra-logical, reducing the advantages brought forward by logic programming.

The roots of LM are the P2 system~\cite{Loo-condie-garofalakis-p2} and
the original Meld
language~\cite{ashley-rollman-derosa-iros07wksp,ashley-rollman-iclp09}. P2
is a Datalog-like language that maps a computer network to a graph,
where each computer node can perform computations locally and
communicate with neighbors. Meld is inspired by the P2 system
but adapted to the concept of massively distributed systems made of
modular robots with a dynamic topology. LM still follows the same
graph model of computation of Meld, which makes LM programs naturally
concurrent since the graph of nodes can be easily partitioned to be
executed by different threads. As a forward-chaining linear logic
programming language, LM also shares similarities with Constraint
Handling Rules
(CHR)~\cite{Betz:2005kx,DBLP:journals/corr/abs-1006-3039}.  CHR is a
concurrent committed-choice constraint language used to write
constraint solvers. A CHR program is a set of rules and a set of
constraints (which can be seen as facts). Constraints can be consumed
or generated during the application of rules. Some optimizations
used in LM such as join optimizations and the use of different data
structures for indexing facts were inspired by research done in
CHR~\cite{DBLP:journals/corr/cs-PL-0408025}.

In this paper, we present the design and implementation of the LM virtual machine
and compiler.
The LM virtual machine was designed from scratch to run LM programs on
multicore machines in an efficient manner\footnote{Source code available at \url{http://github.com/flavioc/meld}}.
The virtual machine is multithreaded and executes byte-code that is generated
by the LM compiler. To test our language and virtual machine we have implemented several graph algorithms, search
algorithms and machine learning algorithms, including: belief
propagation~\cite{Gonzalez+al:aistats09paraml}, belief propagation
with residual splash~\cite{Gonzalez+al:aistats09paraml}, PageRank,
graph coloring, N-Queens, shortest path, diameter estimation, map
reduce, quick-sort, neural network training, minimax, etc.

Our results show that our virtual machine is scalable and presents some interesting
execution times when compared with other competing systems.
The virtual machine uses a simple, but effective, work stealing algorithm
that is able to balance the load across threads, improving scalability.
Another important feature of our virtual machine is the dynamic indexing algorithm.
It is a runtime algorithm that decides how to index logical facts and which
data structure is best to use, so that database lookup and insertion time during rule application
is effectively reduced.

This remainder of the paper is organized as follows. First, we briefly
introduce the LM language. Then, we present an overview of the virtual
machine and describe in more detail the code organization, thread
management, rule execution and database organization. Finally, we
present our experiments and outline some conclusions.
